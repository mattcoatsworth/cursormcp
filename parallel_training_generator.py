"""
Parallel training data generator for MCP

This script runs multiple worker processes in parallel to generate
training data much faster than sequential approaches. Each worker:
1. Generates examples for specific tool/intent combinations
2. Stores examples in local files to minimize DB writes
3. Combines and batch inserts results at the end

Usage:
    python parallel_training_generator.py --workers 4 --examples 1000 --batch-size 50
"""

print("Starting training data generator...")

import os
import json
import time
import random
import argparse
import multiprocessing
from datetime import datetime, timezone
from concurrent.futures import ProcessPoolExecutor, as_completed
import requests
import logging
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv
from supabase import create_client, Client
import pytz
import asyncio
import traceback
from together import Together

# Load environment variables from .env file
load_dotenv()

# Configuration
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY") or "tgp_v1_GfykjlJ8zq5shcMD0eZLYcFjNLkOMh7qtVx-OBjP4mE"  # Replace with your new Together AI API key
MODELS = {
    "llama": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
    "mistral": "mistralai/Mistral-7B-Instruct-v0.2"
}
MODEL = MODELS['mistral']  # Using Mistral 7B Instruct v0.2 model
TEMPERATURE = 0.8
BATCH_SIZE = 5
OUTPUT_DIR = "enhanced_training_data"
QUALITY_MONITORING_DIR = "quality_monitoring"
GPT4_PERCENTAGE = 0.05  # 5% of examples will be generated by GPT-4

# Tool intents mapping - all the different combinations we can generate examples for
TOOL_INTENTS = {
    "Shopify": [
        "Check Order Status", "Update Inventory", "View Sales Report", 
        "Customer Lookup", "Product Search", "Create Discount",
        "Publish Product", "Process Refund", "Update Shipping", "Add Product Tag"
    ],
    "Klaviyo": [
        "Create Email Flow", "Get Open Rates", "Segment Analytics", 
        "Campaign Performance", "List Management", "Create Campaign",
        "Subscription Management", "Trigger Email", "A/B Test Setup", 
        "View Unsubscribe Rate"
    ],
    "Postscript": [
        "Send SMS Campaign", "Check SMS Performance", "Manage SMS Templates", 
        "Subscriber Analytics", "Schedule Message", "Create Automation",
        "View Click Rates", "Manage Compliance", "Subscription Tier Analysis"
    ],
    "Slack": [
        "Send Message", "Create Channel", "Search Messages", "Set Reminder",
        "Share File", "Schedule Message", "Archive Channel", "Add User To Channel",
        "Update Status"
    ],
    "Notion": [
        "Create Page", "Update Database", "Search Documents", "Create Template",
        "Add Comment", "Share Page", "Create Calendar", "Link Pages", "Add Table"
    ],
    "Together AI": [
        "Generate text",
        "Analyze sentiment",
        "Summarize content",
        "Translate text",
        "Generate code",
        "Answer questions",
        "Write documentation",
        "Debug code",
        "Optimize code",
        "Generate tests"
    ],
    "Triple Whale": [
        "Check Ad Performance", "View ROAS", "Analyze Campaign", 
        "Review Metrics", "Generate Report", "Compare Periods"
    ],
    "GitHub": [
        "Create Pull Request", "Review Code", "Merge Branch", 
        "Check Issues", "Add Collaborator", "Clone Repository"
    ],
    "Google Calendar": [
        "Schedule Meeting", "Create Event", "Check Availability", 
        "Set Reminder", "Reschedule Appointment", "Add Participants"
    ]
}

# Cross-service scenarios for more complex examples
CROSS_SERVICE_SCENARIOS = [
    {
        "name": "E-commerce Campaign Analysis",
        "tools": ["Shopify", "Klaviyo", "Triple Whale"],
        "description": "Analyze marketing campaign performance across Shopify orders, Klaviyo email engagement, and Triple Whale ad metrics."
    },
    {
        "name": "Development Project Management", 
        "tools": ["GitHub", "Notion", "Slack"],
        "description": "Coordinate development tasks between GitHub repositories, Notion project docs, and Slack team communication."
    },
    {
        "name": "Marketing Campaign Planning",
        "tools": ["Klaviyo", "Postscript", "Google Calendar"],
        "description": "Plan and schedule marketing campaigns across email (Klaviyo), SMS (Postscript), and team calendars."
    },
    {
        "name": "Content Creation Workflow",
        "tools": ["Together AI", "Notion", "Slack"],
        "description": "Generate content with AI, organize in Notion, and share with team via Slack."
    }
]

# Response generation guidelines
RESPONSE_GUIDELINES = """
1. Always provide clear, concise, and user-friendly responses
2. Never include technical terms or jargon
3. Never voluntarily direct users to external documentation or websites
4. Only provide external references when explicitly asked by the user
5. Always include step-by-step guidance
6. Always provide practical examples
7. Use simple, everyday language
8. Focus on actionable steps
9. Never mention APIs, endpoints, or technical implementation details
10. Never proactively suggest visiting external resources
11. Keep responses focused on the user's specific question
12. Provide complete solutions without external references by default
13. Use a conversational, helpful tone
14. Break down complex tasks into simple steps
15. Include relevant examples and use cases
16. Ensure all information is self-contained within the response unless specifically asked for external references
"""

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('parallel_training_generator.log'),
        logging.StreamHandler()
    ]
)

# Initialize Supabase client
supabase_url = os.getenv('SUPABASE_URL')
supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')  # Use service role key instead of anon key
if not supabase_url or not supabase_key:
    raise ValueError("Supabase credentials not found in environment variables")
logging.info(f"Initializing Supabase client with URL: {supabase_url}")
supabase: Client = create_client(supabase_url, supabase_key)

# Test Supabase connection
try:
    logging.info("Testing Supabase connection...")
    result = supabase.table('training_data').select("count").limit(1).execute()
    logging.info("Successfully connected to Supabase")
except Exception as e:
    logging.error(f"Failed to connect to Supabase: {str(e)}")
    raise

class QualityValidator:
    def __init__(self):
        # Technical terms that should not appear in user-facing responses
        self.technical_terms = [
            'api', 'endpoint', 'authentication', 'token', 'request', 'implementation',
            'integration', 'webhook', 'callback', 'sdk', 'framework', 'database',
            'server', 'client', 'protocol', 'http', 'https', 'json', 'xml',
            'rest', 'soap', 'oauth', 'jwt', 'cors', 'rate limit', 'timeout',
            'error handling', 'exception', 'stack trace', 'debug', 'log',
            'configuration', 'environment variable', 'deployment', 'hosting'
        ]
        
        # Phrases that should not appear in responses
        self.forbidden_phrases = [
            'if you need more details go to',
            'for more information visit',
            'check out our documentation at',
            'refer to our docs',
            'see our documentation',
            'visit our website',
            'go to our website',
            'check our website',
            'visit us at',
            'go to',
            'check out',
            'refer to',
            'see',
            'visit'
        ]
        
        # Required elements in responses
        self.required_elements = [
            'clear explanation',
            'step-by-step guidance',
            'practical examples',
            'user-friendly language',
            'actionable steps'
        ]

    def calculate_response_parameters(self, response: str) -> Dict[str, Any]:
        """Calculate response parameters for metadata"""
        response_lower = response.lower()
        
        # Check for technical terms
        has_technical_terms = any(term in response_lower for term in self.technical_terms)
        
        # Check for forbidden phrases
        has_external_references = any(phrase in response_lower for phrase in self.forbidden_phrases)
        
        # Check for required elements
        has_step_by_step = any('step' in response_lower or 'first' in response_lower or 'next' in response_lower)
        has_practical_examples = any('example' in response_lower or 'for instance' in response_lower or 'like' in response_lower)
        uses_simple_language = not has_technical_terms and len(response.split()) > 0
        has_actionable_steps = has_step_by_step and any('do this' in response_lower or 'follow these' in response_lower)
        
        # Calculate quality score (0-1)
        quality_score = 0.0
        if not has_technical_terms: quality_score += 0.2
        if not has_external_references: quality_score += 0.2
        if has_step_by_step: quality_score += 0.2
        if has_practical_examples: quality_score += 0.2
        if has_actionable_steps: quality_score += 0.2
        
        return {
            "is_user_friendly": not has_technical_terms and not has_external_references,
            "has_step_by_step_guidance": has_step_by_step,
            "has_practical_examples": has_practical_examples,
            "uses_simple_language": uses_simple_language,
            "has_actionable_steps": has_actionable_steps,
            "is_self_contained": not has_external_references,
            "has_external_references": has_external_references,
            "has_technical_terms": has_technical_terms,
            "response_length": len(response),
            "has_error_handling": "error" in response_lower or "if something goes wrong" in response_lower,
            "quality_score": quality_score,
            "validation_status": "valid" if quality_score >= 0.8 else "needs_improvement"
        }

    def validate_quality(self, example: Dict[str, Any]) -> bool:
        """Validate the quality of a generated example."""
        try:
            # Check required fields
            required_fields = ['tool', 'intent', 'query', 'response', 'systems', 'workflow']
            if not all(field in example for field in required_fields):
                return False

            # Check response length
            if len(example['response']) < 50:
                return False

            # Calculate response parameters
            response_params = self.calculate_response_parameters(example['response'])
            
            # Update example metadata with response parameters
            if 'metadata' not in example:
                example['metadata'] = {}
            example['metadata'].update(response_params)

            # Check for technical terms in response
            if response_params['has_technical_terms']:
                return False

            # Check for forbidden phrases
            if response_params['has_external_references']:
                return False

            # Check for required elements
            if not response_params['has_step_by_step_guidance']:
                return False

            # Check workflow structure
            if not isinstance(example['workflow'], list):
                return False

            # Check each step in workflow
            for step in example['workflow']:
                if not isinstance(step, dict):
                    return False
                if 'action' not in step or 'parameters' not in step:
                    return False
                if not isinstance(step['parameters'], dict):
                    return False

            return True

        except Exception as e:
            print(f"Error validating example: {str(e)}")
            return False

    @staticmethod
    def log_quality_metrics(example: Dict, model: str):
        """Log quality metrics for monitoring."""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'model': model,
            'response_length': len(example['response']),
            'has_execution_details': bool(example.get('execution_details')),
            'is_user_friendly': not any(term in example['response'].lower() for term in ['api', 'endpoint', 'authentication', 'token']),
            'has_error_handling': 'error_handling' in example.get('execution_details', {})
        }
        
        os.makedirs(QUALITY_MONITORING_DIR, exist_ok=True)
        metrics_file = os.path.join(QUALITY_MONITORING_DIR, 'quality_metrics.jsonl')
        
        with open(metrics_file, 'a') as f:
            f.write(json.dumps(metrics) + '\n')

class TrainingGenerator:
    def __init__(self):
        self.validator = QualityValidator()
        self.client = Together(api_key=TOGETHER_API_KEY)
        self.system_prompt = """You are helping generate realistic training data for a comprehensive business operations management system.
        Generate realistic queries from the perspective of founders and executives using this system to manage their entire business operations through a unified chat interface.
        
        IMPORTANT: Return ONLY a JSON array with this exact format:
        [
            {
                "query": "user query here",
                "response": "helpful response here"
            }
        ]
        
        Do not include any other text, explanations, or formatting.
        Each query should be from the perspective of a founder or executive managing their business operations.
        The queries should focus on managing the entire tech stack and business operations through the chat interface.
        The system is designed for comprehensive business operations management, not for direct customer interactions."""
        self.total_examples = 0
        self.valid_examples = 0
        self.gpt4_examples = 0
        self.supabase = supabase
        
    def get_system_prompt(self, tool: str, intent: str) -> str:
        """Get the system prompt for a specific tool and intent."""
        prompts = {
            "Shopify": {
                "Check Order Status": """You are a helpful assistant for Shopify order status inquiries. Follow these guidelines:

1. Response Structure:
   - Always include current order status
   - Include expected shipping/delivery dates
   - Mention any issues or delays
   - Provide tracking info when available

2. Email Updates:
   - Only offer email updates when there's an actual issue or delay
   - Don't offer email updates for routine status checks

3. Follow-up Handling:
   - Generate natural follow-up queries and responses
   - Include both positive and negative follow-up scenarios
   - Maintain context between follow-ups

4. Supplier Contact:
   - Save supplier contact details when provided
   - Reference saved supplier info in future responses
   - Don't recommend contacting carriers for routine shipping inquiries

5. Response Quality:
   - Provide detailed, helpful information
   - Be proactive with relevant follow-up questions
   - Maintain a friendly, professional tone"""
            }
        }
        return prompts.get(tool, {}).get(intent, "")

    async def generate_examples_batch(self, tool: str, intent: str, count: int = 5) -> List[Dict]:
        """Generate a batch of examples for a given tool and intent"""
        examples = []
        max_retries = 3
        base_delay = 2  # Base delay in seconds
        
        for attempt in range(max_retries):
            try:
                # Add exponential backoff delay between attempts
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    print(f"Retrying after {delay} seconds...")
                    await asyncio.sleep(delay)
                
                # Add a small delay between API calls to avoid rate limiting
                await asyncio.sleep(1)
                
                response = await self.client.chat.completions.create(
                    model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": f"""Generate {count} different example user queries for {tool} with intent {intent}.
                        Each query should be unique and natural-sounding.
                        Return the queries as a JSON array of strings."""}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                
                if response and response.choices:
                    try:
                        queries = json.loads(response.choices[0].message.content)
                        if isinstance(queries, list):
                            for query_text in queries:
                                examples.append({
                                    "query": query_text,
                                    "response": "Sample response",  # This will be replaced with actual response
                                    "tool": tool,
                                    "intent": intent,
                                    "systems": [tool],
                                    "workflow": [intent],
                                    "metadata": {
                                        "generated_at": datetime.now(pytz.timezone('America/New_York')).isoformat(),
                                        "source": "training_generator",
                                        "quality_score": 0.8,
                                        "validation_status": "pending"
                                    }
                                })
                            break  # Successfully generated examples, exit retry loop
                    except json.JSONDecodeError as e:
                        print(f"Error parsing response as JSON: {e}")
                        print(f"Raw response: {response.choices[0].message.content}")
                        continue
                
            except Exception as e:
                print(f"Error generating examples (attempt {attempt + 1}/{max_retries}): {str(e)}")
                if attempt == max_retries - 1:
                    print("Max retries reached, giving up")
                    break
                continue
        
        return examples

    def generate_cross_service_examples(self, scenario, count, batch_size=10, worker_id=0):
        """
        Generate examples for cross-service scenarios
        
        Args:
            scenario (dict): The scenario information
            count (int): Number of examples to generate
            batch_size (int): Number of examples per batch
            worker_id (int): ID of the worker process
            
        Returns:
            list: The generated examples
        """
        all_examples = []
        tools_str = ", ".join(scenario["tools"])
        
        # Calculate number of batches needed
        num_batches = (count + batch_size - 1) // batch_size
        
        for batch_idx in range(num_batches):
            # Calculate actual batch size (might be smaller for last batch)
            current_batch_size = min(batch_size, count - batch_idx * batch_size)
            
            system_prompt = f"""
            You are helping generate realistic training data for a multi-service assistant.
            Generate {current_batch_size} different realistic user queries that require using multiple services: {tools_str}.
            These queries should be for the scenario: {scenario["name"]} - {scenario["description"]}
            
            For each query, also provide a professional, helpful response that addresses the query.
            Format your response as a JSON array where each item has "query" and "response" fields.
            
            Make sure each query explicitly mentions at least 2 of these services: {tools_str}.
            The queries should have diverse wording, specificity, and complexity.
            """
            
            try:
                # Call Together AI API
                headers = {
                    "Authorization": f"Bearer {TOGETHER_API_KEY}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": MODELS['mistral'],
                    "prompt": f"<system>{system_prompt}</system><user>Generate {current_batch_size} cross-service queries for scenario: {scenario['name']}</user><assistant>",
                    "temperature": TEMPERATURE,
                    "max_tokens": 2500,
                    "stop": ["</assistant>"]
                }
                
                response = requests.post(
                    "https://api.together.xyz/inference",
                    headers=headers,
                    json=data
                )
                
                if response.status_code != 200:
                    print(f"Worker {worker_id}: API call failed with status {response.status_code}: {response.text}")
                    continue
                    
                # Parse response
                try:
                    content = response.json()["output"]["choices"][0]["text"]
                    examples_json = json.loads(content)
                    
                    # Extract examples
                    if "examples" in examples_json:
                        batch_examples = examples_json["examples"]
                    else:
                        # Sometimes the model returns an array directly
                        batch_examples = examples_json.get("data", [])
                        if not batch_examples and isinstance(examples_json, list):
                            batch_examples = examples_json
                    
                    # Add metadata
                    for example in batch_examples:
                        example["scenario"] = scenario["name"]
                        example["tools"] = scenario["tools"]
                        example["created_at"] = datetime.now().isoformat()
                        example["is_multi_service"] = True
                    
                    all_examples.extend(batch_examples)
                    
                    print(f"Worker {worker_id}: Generated {len(batch_examples)} examples for scenario {scenario['name']} (Batch {batch_idx+1}/{num_batches})")
                    
                except json.JSONDecodeError as e:
                    print(f"Worker {worker_id}: Failed to parse response as JSON: {str(e)}")
                    print(f"Raw response: {content}")
                    continue
                
                # Small pause to avoid rate limits
                time.sleep(0.2)
                
            except Exception as e:
                print(f"Worker {worker_id}: Error generating examples for scenario {scenario['name']} (Batch {batch_idx+1}): {str(e)}")
                time.sleep(1)  # Wait a bit longer on error
        
        return all_examples

    def print_quality_report(self):
        """Print a quality report of the generated data."""
        logging.info("\n=== Quality Report ===")
        logging.info(f"Total examples generated: {self.total_examples}")
        logging.info(f"Valid examples: {self.valid_examples}")
        logging.info(f"Validation rate: {(self.valid_examples/self.total_examples)*100:.2f}%")
        logging.info(f"GPT-4 examples: {self.gpt4_examples}")
        logging.info(f"GPT-4 percentage: {(self.gpt4_examples/self.total_examples)*100:.2f}%")
        logging.info("===================\n")

    def store_training_data(self, examples, tool, intent):
        """Store training data in Supabase"""
        try:
            # Prepare data for Supabase
            training_data = []
            for example in examples:
                # Extract execution details
                execution_details = example.get("execution_details", {})
                
                # Create training data entry
                training_entry = {
                    "query": example["query"],
                    "response": example["response"],
                    "systems": [tool],  # Array of systems/tools
                    "workflow": [intent],  # Array of workflows/intents
                    "metadata": {
                        "api_endpoint": execution_details.get("api_endpoint", ""),
                        "authentication": execution_details.get("authentication", ""),
                        "implementation": execution_details.get("implementation", ""),
                        "error_handling": execution_details.get("error_handling", ""),
                        "created_by": "parallel_training_generator"
                    }
                }
                training_data.append(training_entry)
            
            # Store in Supabase
            result = self.supabase.table("training_data").insert(training_data).execute()
            
            if hasattr(result, "error") and result.error:
                print(f"Error storing training data: {result.error}")
            else:
                print(f"Successfully stored {len(training_data)} training examples for {tool} - {intent}")
                
        except Exception as e:
            print(f"Error storing training data: {str(e)}")
            print(f"Data that failed to store: {training_data}")

def ensure_tables_exist():
    """Create necessary tables in Supabase if they don't exist."""
    try:
        # Create api_endpoints table
        supabase.table('api_endpoints').select("count").limit(1).execute()
        logging.info("api_endpoints table exists")
    except Exception as e:
        logging.info("Creating api_endpoints table...")
        supabase.rpc('create_api_endpoints_table').execute()

    try:
        # Create training_data table
        supabase.table('training_data').select("count").limit(1).execute()
        logging.info("training_data table exists")
    except Exception as e:
        logging.info("Creating training_data table...")
        supabase.rpc('create_training_data_table').execute()

def store_system_context():
    """Store system-wide context and rules in the training_data table."""
    try:
        # Get current timestamp in UTC
        current_time = datetime.now(timezone.utc)
        
        # Define the system context with all prompts and guidelines
        system_context = {
            "rules": {
                "query_guidelines": [
                    "Use natural, conversational language that real business owners would actually say",
                    "Never write queries from a customer's perspective (e.g., 'I placed an order')",
                    "Always write queries from the business owner's perspective (e.g., 'Check the status of order #123456')",
                    "Never use formal business language or corporate speak",
                    "Write queries as if you're texting or chatting with a colleague",
                    "Be direct and specific about what you need",
                    "Use everyday business language",
                    "Include relevant details like order numbers, dates, or specific products",
                    "Never use artificial or overly formal language"
                ],
                "response_guidelines": [
                    "Keep responses concise and direct",
                    "Always include the current order status",
                    "Include expected shipping/delivery dates when available",
                    "Mention any issues or delays that need attention",
                    "Provide tracking information when available",
                    "Include order value and items when relevant",
                    "Only offer email updates when there's an actual issue or delay",
                    "For multiple order queries, provide a clear summary with status for each order",
                    "Include any relevant notes about customer communication or special handling",
                    "Mention any required actions or follow-ups needed",
                    "When dealing with suppliers, always check for saved contact information first",
                    "If supplier contact details are saved, reference them by name in responses",
                    "If supplier contact details are not saved, ask for them before taking action",
                    "Save supplier contact details when provided for future reference",
                    "Never recommend contacting carriers for shipping speed changes after pickup",
                    "Only suggest carrier contact for actual issues like lost packages or delivery exceptions",
                    "For shipping delays, focus on providing accurate delivery estimates rather than suggesting carrier contact",
                    "Never ask customers to confirm their shipping address or provide additional information",
                    "Never include unnecessary follow-up questions or requests for information",
                    "Keep responses focused on the specific query without adding extra context or questions"
                ],
                "shipping_guidelines": [
                    "Never recommend contacting carriers for routine shipping inquiries",
                    "Only suggest carrier contact for actual issues (lost packages, delivery exceptions)",
                    "For shipping delays, provide accurate delivery estimates and tracking information",
                    "Never suggest carrier contact for shipping speed changes after pickup",
                    "Focus on providing clear delivery timelines rather than suggesting carrier outreach",
                    "For shipping issues, first check tracking and delivery status before suggesting any actions"
                ],
                "supplier_contact_guidelines": [
                    "Always check for saved supplier contact information before asking for it",
                    "When supplier contact details are saved, use them in responses: 'Would you like me to email [supplier_name] about...'",
                    "When no supplier contact details are saved, ask for them: 'If you provide the contact details of the supplier, I can send them an email.'",
                    "After receiving supplier contact details, save them with context about the task",
                    "Include supplier name and task context when saving contact details",
                    "Reference saved supplier details in future similar interactions",
                    "Never assume supplier contact details are available without checking first"
                ],
                "email_update_rules": [
                    "Only offer email updates when there's an actual issue or delay",
                    "Never offer email updates for routine order status checks",
                    "Never offer email updates for multiple order status listings",
                    "Only offer email updates when the order status indicates a problem",
                    "Include specific details about what the email update will contain",
                    "When user confirms email update, provide a follow-up response confirming the action",
                    "Include relevant order details in the confirmation response",
                    "Never mention technical details about email sending or API calls",
                    "Keep the response focused on the customer communication aspect"
                ],
                "response_format": [
                    "Start with the current order status",
                    "Include expected dates (shipping/delivery)",
                    "Add any relevant details (value, items, tracking)",
                    "Mention any issues or required actions",
                    "Only offer email updates if there's an actual issue"
                ]
            },
            "examples": {
                "good_responses": [
                    {
                        "query": "Check the status of order #123456",
                        "response": "Order #123456 is currently in 'Preparation' status. It was placed on March 15th with a total value of $299.99. The order includes 2 'Eco-Friendly Towels' sets and is expected to ship on March 23rd. There are no issues or delays reported.",
                        "supplier_contact_used": False
                    },
                    {
                        "query": "What's happening with order #789012? It's been in processing for 5 days.",
                        "response": "Order #789012 is still in 'Processing' status after 5 days, which is longer than usual. The order was placed on March 10th for $499.99. I've identified a potential issue with the supplier's inventory. Would you like me to send an email update to the customer explaining the delay?",
                        "supplier_contact_used": False
                    },
                    {
                        "query": "Yes, please send the email update",
                        "response": "I've sent an email to Sarah Johnson (customer for order #789012) explaining the delay. The email includes the current status, the supplier inventory issue, and our estimated resolution time of 2-3 business days. I'll notify you once we receive a response from the supplier.",
                        "supplier_contact_used": False,
                        "is_follow_up": True,
                        "previous_query": "What's happening with order #789012? It's been in processing for 5 days."
                    },
                    {
                        "query": "Check the status of order #123456",
                        "response": "Order #123456 is currently in 'Shipping' status but has been delayed due to weather conditions. The order was placed on March 15th for $299.99 and was expected to arrive on March 20th. The new estimated delivery date is March 23rd. Would you like me to send an email update to the customer about this delay?",
                        "supplier_contact_used": False
                    },
                    {
                        "query": "Yes, send them an update",
                        "response": "I've sent an email to Michael Chen (customer for order #123456) about the shipping delay. The email includes the current status, the weather-related delay, and the new estimated delivery date of March 23rd. I've also included the tracking number for their reference.",
                        "supplier_contact_used": False,
                        "is_follow_up": True,
                        "previous_query": "Check the status of order #123456"
                    },
                    {
                        "query": "We need to reorder the Eco-Friendly Towels, we're running low",
                        "response": "The Eco-Friendly Towels inventory is running low. Current stock is 500 units with a sell-through rate of 100 units per day. At this rate, we'll be out of stock in 5 days. I recommend ordering 1,000 units to maintain a 10-day buffer. If you provide the contact details of the supplier, I can send them an email.",
                        "supplier_contact_used": False
                    },
                    {
                        "query": "Here are the supplier details for Eco-Friendly Towels: John Smith at EcoSupplies Inc., email: john@ecosupplies.com",
                        "response": "I've saved the contact details for Eco-Friendly Towels supplier: John Smith at EcoSupplies Inc. I'll send them an email to place an order for 1,000 units. Would you like me to proceed with sending the order request?",
                        "supplier_contact_used": True,
                        "is_follow_up": True,
                        "previous_query": "We need to reorder the Eco-Friendly Towels, we're running low"
                    },
                    {
                        "query": "Yes, please send the order request",
                        "response": "I've sent the order request to John at EcoSupplies Inc. for 1,000 units of Eco-Friendly Towels. I'll notify you once I receive their confirmation.",
                        "supplier_contact_used": True,
                        "is_follow_up": True,
                        "previous_query": "Here are the supplier details for Eco-Friendly Towels: John Smith at EcoSupplies Inc., email: john@ecosupplies.com"
                    },
                    {
                        "query": "No, don't send the order yet",
                        "response": "Understood. I've saved the supplier contact details for future use. Let me know when you'd like to proceed with the order.",
                        "supplier_contact_used": True,
                        "is_follow_up": True,
                        "previous_query": "Here are the supplier details for Eco-Friendly Towels: John Smith at EcoSupplies Inc., email: john@ecosupplies.com"
                    }
                ],
                "bad_responses": [
                    {
                        "query": "Check order #123456",
                        "response": "The order is in preparation. Would you like me to send an email update?",
                        "issues": ["Too short", "Offers email update unnecessarily"]
                    },
                    {
                        "query": "Show me our last 3 orders",
                        "response": "Here are the orders:\n1. Order #123: Processing\n2. Order #456: Shipped\n3. Order #789: Delivered",
                        "issues": ["Missing important details", "Too brief"]
                    },
                    {
                        "query": "We need to reorder the Eco-Friendly Towels",
                        "response": "I'll place an order for 1,000 units right away.",
                        "issues": ["Assumes supplier contact details are available", "Doesn't check for saved contacts"]
                    },
                    {
                        "query": "Check the status of order #123456",
                        "response": "The order from 'EcoCorp' for 1,000 units of 'Eco-Friendly Towels' is in 'Shipping Preparation'. It is expected to ship on March 25th and arrive on March 28th. I recommend contacting our carrier to ensure the priority shipping request was applied to expedite delivery.",
                        "issues": ["Incorrectly suggests carrier contact for normal shipping", "Recommends unnecessary carrier outreach"]
                    },
                    {
                        "query": "Here are the supplier details for Eco-Friendly Towels: John Smith at EcoSupplies Inc., email: john@ecosupplies.com",
                        "response": "I'll send the order request right away.",
                        "issues": ["Doesn't confirm the details were saved", "Doesn't ask for confirmation before sending", "Assumes user wants to proceed immediately"]
                    },
                    {
                        "query": "Yes, please send the email update",
                        "response": "I've sent the email through our notification system.",
                        "issues": ["Doesn't mention who the email was sent to", "Doesn't include order details", "Too vague about what was communicated"]
                    },
                    {
                        "query": "Yes, send them an update",
                        "response": "I've triggered the email notification API endpoint for order #123456.",
                        "issues": ["Mentions technical implementation details", "Doesn't specify what was communicated", "Doesn't mention the customer"]
                    }
                ]
            },
            "version_history": [
                {
                    "version": "1.4",
                    "date": "2024-03-20T22:00:00Z",
                    "changes": [
                        "Updated email notification guidelines to only offer updates when there's an actual issue",
                        "Added clarification about not offering email updates for routine order status checks",
                        "Updated example responses to reflect new email notification guidelines"
                    ]
                },
                {
                    "version": "1.5",
                    "date": current_time.isoformat(),
                    "changes": [
                        "Added specific guideline about not offering email updates for multiple order status listings",
                        "Added example of correct response for multiple order status queries",
                        "Updated response guidelines to clarify when to offer email updates",
                        "Added detailed response format guidelines",
                        "Enhanced examples with more comprehensive responses",
                        "Added supplier contact handling guidelines",
                        "Added examples of good and bad supplier contact handling",
                        "Added guidelines for saving and referencing supplier contact information",
                        "Added shipping guidelines to prevent unnecessary carrier contact recommendations",
                        "Added example of incorrect carrier contact recommendation",
                        "Updated response guidelines to focus on accurate delivery estimates rather than carrier outreach",
                        "Removed verbose response patterns and unnecessary follow-up questions",
                        "Added guidelines to keep responses concise and direct",
                        "Added examples of good concise responses",
                        "Added guidelines to prevent customer-facing language and unnecessary information requests"
                    ]
                },
                {
                    "version": "1.6",
                    "date": current_time.isoformat(),
                    "changes": [
                        "Added examples of supplier contact follow-up interactions",
                        "Added guidelines for handling supplier contact information in follow-up responses",
                        "Added examples of good and bad follow-up responses for supplier contact scenarios"
                    ]
                },
                {
                    "version": "1.7",
                    "date": current_time.isoformat(),
                    "changes": [
                        "Added examples of email notification follow-up responses",
                        "Added guidelines for confirming email notifications",
                        "Added examples of good and bad email notification confirmations",
                        "Updated email update rules to include follow-up response guidelines"
                    ]
                }
            ],
            "metadata": {
                "last_updated": current_time.isoformat(),
                "version": "1.7",
                "source": "system_prompt_refinements",
                "purpose": "Training data for improving system responses"
            }
        }
        
        # Create a context example that represents the system context
        context_example = {
            "query": "SYSTEM_CONTEXT",
            "response": "System context and guidelines for generating high-quality responses",
            "tool": "system",
            "intent": "training_guidelines",
            "systems": ["all"],
            "workflow": ["system_training"],
            "execution_details": {
                "timestamp": current_time.isoformat(),
                "type": "system_context",
                "version": "1.7"
            },
            "metadata": system_context
        }
        
        # Insert the context example into the training_data table
        response = supabase.table("training_data").insert(context_example).execute()
        
        if response.data:
            logging.info("Successfully stored system context and rules")
        else:
            logging.error("Failed to store system context")
            
    except Exception as e:
        logging.error(f"Error storing system context: {str(e)}")
        raise

def store_api_endpoints():
    """Store API endpoints and their details in Supabase."""
    try:
        logging.info("Importing endpoints from api_endpoints.py...")
        from api_endpoints import (
            SHOPIFY_ENDPOINTS,
            KLAVIYO_ENDPOINTS,
            POSTSCRIPT_ENDPOINTS,
            GORGIAS_ENDPOINTS,
            NORTHBEAM_ENDPOINTS,
            TRIPLE_WHALE_ENDPOINTS,
            ELEVAR_ENDPOINTS,
            NOTION_ENDPOINTS,
            GOOGLE_CALENDAR_ENDPOINTS,
            ASANA_ENDPOINTS,
            GOOGLE_DRIVE_ENDPOINTS,
            FIGMA_ENDPOINTS,
            SLACK_ENDPOINTS
        )
        logging.info("Endpoints imported successfully")
        
        # Process each service's endpoints
        all_endpoints = [
            ("Shopify", SHOPIFY_ENDPOINTS),
            ("Klaviyo", KLAVIYO_ENDPOINTS),
            ("Postscript", POSTSCRIPT_ENDPOINTS),
            ("Gorgias", GORGIAS_ENDPOINTS),
            ("Northbeam", NORTHBEAM_ENDPOINTS),
            ("Triple Whale", TRIPLE_WHALE_ENDPOINTS),
            ("Elevar", ELEVAR_ENDPOINTS),
            ("Notion", NOTION_ENDPOINTS),
            ("Google Calendar", GOOGLE_CALENDAR_ENDPOINTS),
            ("Asana", ASANA_ENDPOINTS),
            ("Google Drive", GOOGLE_DRIVE_ENDPOINTS),
            ("Figma", FIGMA_ENDPOINTS),
            ("Slack", SLACK_ENDPOINTS)
        ]
        
        total_endpoints = 0
        for service_name, service_endpoints in all_endpoints:
            logging.info(f"Processing endpoints for {service_name}...")
            for category, category_endpoints in service_endpoints.items():
                for action, endpoint_data in category_endpoints.items():
                    try:
                        # Construct full endpoint URL
                        base_url = {
                            "Shopify": "https://{shop_name}.myshopify.com",
                            "Klaviyo": "https://a.klaviyo.com",
                            "Postscript": "https://api.postscript.io",
                            "Gorgias": "https://api.gorgias.com",
                            "Northbeam": "https://api.northbeam.io",
                            "Triple Whale": "https://api.triplewhale.com",
                            "Elevar": "https://api.getelevar.com",
                            "Notion": "https://api.notion.com",
                            "Google Calendar": "https://www.googleapis.com/calendar/v3",
                            "Asana": "https://app.asana.com/api/1.0",
                            "Google Drive": "https://www.googleapis.com/drive/v3",
                            "Figma": "https://api.figma.com/v1",
                            "Slack": "https://slack.com/api"
                        }.get(service_name, f"https://{service_name.lower().replace(' ', '')}.com")
                        
                        endpoint = f"{base_url}{endpoint_data['path']}"
                        
                        # Prepare parameters
                        parameters = endpoint_data.get('parameters', {})
                        
                        # Get authentication details
                        auth = endpoint_data.get('auth', {})
                        auth_type = auth.get('type', 'Unknown')
                        
                        # Get rate limit
                        rate_limit = endpoint_data.get('rate_limit', 'Not specified')
                        
                        # Get response format if available
                        response_format = endpoint_data.get('response_format', {})
                        
                        # Insert or update endpoint using Supabase upsert
                        data = {
                            "service": service_name,
                            "resource": category,
                            "action": action,
                            "method": endpoint_data['method'],
                            "path": endpoint_data['path'],
                            "parameters": parameters,
                            "auth_type": auth_type,
                            "auth_key": auth.get('key', 'Unknown'),
                            "rate_limit": rate_limit,
                            "created_at": datetime.now().isoformat()
                        }
                        
                        result = supabase.table('api_endpoints').upsert(data).execute()
                        total_endpoints += 1
                        
                    except Exception as e:
                        logging.error(f"Error processing endpoint for {service_name} - {category} - {action}: {str(e)}")
                        continue
        
        logging.info(f"Successfully stored {total_endpoints} API endpoints for all services")
        
        # Verify the data was stored
        result = supabase.table('api_endpoints').select('count').execute()
        count = result.data[0]['count'] if result.data else 0
        logging.info(f"Total endpoints in database: {count}")
        
    except Exception as e:
        logging.error(f"Error storing API endpoints: {str(e)}")
        raise

def standardize_metadata(metadata: Dict, model: str) -> Dict:
    """Standardize metadata for training data insertion"""
    # Get current UTC timestamp and convert to EST
    utc_time = datetime.now(timezone.utc)
    est_time = utc_time.astimezone(timezone.timezone('America/New_York'))
    current_time = est_time.isoformat()
    
    standardized = {
        "source": metadata.get("source", "parallel_training_generator"),
        "generated_at": metadata.get("generated_at", current_time),
        "model": model,
        "is_multi_service": metadata.get("is_multi_service", False),
        "services_required": metadata.get("services_required", []),
        "scenario": metadata.get("scenario", ""),
        "description": metadata.get("description", ""),
        "complexity": metadata.get("complexity", "medium"),
        "response_parameters": {
            "is_user_friendly": metadata.get("is_user_friendly", True),
            "has_step_by_step_guidance": metadata.get("has_step_by_step_guidance", True),
            "has_practical_examples": metadata.get("has_practical_examples", True),
            "uses_simple_language": metadata.get("uses_simple_language", True),
            "has_actionable_steps": metadata.get("has_actionable_steps", True),
            "is_self_contained": metadata.get("is_self_contained", True),
            "has_external_references": metadata.get("has_external_references", False),
            "has_technical_terms": metadata.get("has_technical_terms", False),
            "response_length": metadata.get("response_length", 0),
            "has_error_handling": metadata.get("has_error_handling", True),
            "quality_score": metadata.get("quality_score", 0.0),
            "validation_status": metadata.get("validation_status", "valid")
        }
    }
    return standardized

def insert_examples_to_db(examples: List[Dict]) -> int:
    """Insert examples into the training_data table."""
    if not examples:
        return 0
        
    logging.info(f"Attempting to insert {len(examples)} examples into database")
    
    try:
        # Get current time in UTC
        current_time = datetime.now().isoformat()
        
        # Prepare data for insertion
        training_data = []
        for example in examples:
            training_data.append({
                "query": example["query"],
                "response": example["response"],
                "tool": example["tool"],
                "intent": example["intent"],
                "systems": example["systems"],
                "workflow": example["workflow"],
                "execution_details": example["execution_details"],
                "metadata": {
                    **example.get("metadata", {}),
                    "generated_at": current_time
                },
                "created_at": current_time
            })
            
        # Insert data into Supabase
        result = supabase.table("training_data").insert(training_data).execute()
        
        if hasattr(result, 'data'):
            inserted_count = len(result.data)
            logging.info(f"Successfully inserted {inserted_count} examples")
            return inserted_count
        else:
            logging.error("No data returned from insert operation")
            return 0
            
    except Exception as e:
        logging.error(f"Error inserting examples into database: {str(e)}")
        logging.error(f"Data that failed to store: {training_data}")
        return 0

def worker_process(worker_id, work_items, examples_per_item, batch_size, output_dir):
    """
    Worker process that generates examples for assigned work items
    
    Args:
        worker_id (int): ID of this worker process
        work_items (list): List of (tool, intent) tuples or scenario dicts to process
        examples_per_item (int): Number of examples to generate per work item
        batch_size (int): Batch size for API calls
        output_dir (str): Directory to save output files
        
    Returns:
        int: Count of examples generated
    """
    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    total_examples = 0
    
    # Process each assigned work item
    for idx, item in enumerate(work_items):
        examples = []
        
        if isinstance(item, tuple):
            # Single-service example
            tool, intent = item
            print(f"Worker {worker_id}: Starting generation for {tool} - {intent} ({idx+1}/{len(work_items)})")
            examples = generate_examples_batch(
                tool, intent, examples_per_item, batch_size, worker_id
            )
            
            # Save to a tool-intent specific file
            if examples:
                output_file = os.path.join(output_dir, f"worker{worker_id}_{tool}_{intent.replace(' ', '_')}_{len(examples)}.json")
                with open(output_file, 'w') as f:
                    json.dump(examples, f, indent=2)
                
                total_examples += len(examples)
        else:
            # Cross-service example
            scenario = item
            print(f"Worker {worker_id}: Starting generation for scenario {scenario['name']} ({idx+1}/{len(work_items)})")
            examples = generate_cross_service_examples(
                scenario, examples_per_item, batch_size, worker_id
            )
            
            # Save to a scenario-specific file
            if examples:
                output_file = os.path.join(output_dir, f"worker{worker_id}_scenario_{scenario['name'].replace(' ', '_')}_{len(examples)}.json")
                with open(output_file, 'w') as f:
                    json.dump(examples, f, indent=2)
                
                total_examples += len(examples)
        
        # Small delay between work items to avoid rate limits
        time.sleep(0.5)
    
    return total_examples

def process_output_files(output_dir):
    """
    Process all output files and insert them into the database
    
    Args:
        output_dir (str): Directory containing output files
        
    Returns:
        int: Total number of examples inserted
    """
    total_inserted = 0
    
    try:
        # Get all JSON files in the output directory
        json_files = [f for f in os.listdir(output_dir) if f.endswith('.json')]
        print(f"Found {len(json_files)} output files to process")
        
        # Process each file
        for file_name in json_files:
            file_path = os.path.join(output_dir, file_name)
            try:
                with open(file_path, 'r') as f:
                    examples = json.load(f)
                
                # Insert examples from this file
                inserted = insert_examples_to_db(examples)
                total_inserted += inserted
                
                print(f"Inserted {inserted} examples from {file_name}")
                
                # Optionally move or delete the file after processing
                # os.rename(file_path, os.path.join(output_dir, "processed", file_name))
                
            except Exception as e:
                print(f"Error processing file {file_name}: {str(e)}")
        
        return total_inserted
    
    except Exception as e:
        logging.error(f"Error processing output files: {str(e)}")
        return 0

def distribute_work(num_workers, include_cross_service=True):
    """
    Distribute work items among workers
    
    Args:
        num_workers (int): Number of worker processes
        include_cross_service (bool): Whether to include cross-service scenarios
        
    Returns:
        list: List of work items for each worker
    """
    # Create a list of all possible (tool, intent) combinations
    single_service_work = []
    for tool, intents in TOOL_INTENTS.items():
        for intent in intents:
            single_service_work.append((tool, intent))
    
    # Shuffle to distribute work evenly
    random.shuffle(single_service_work)
    
    # Add cross-service scenarios if requested
    all_work = single_service_work.copy()
    if include_cross_service:
        all_work.extend(CROSS_SERVICE_SCENARIOS)
        random.shuffle(all_work)
    
    # Distribute work among workers
    work_per_worker = []
    for i in range(num_workers):
        # Each worker gets approximately the same number of items
        worker_items = [item for idx, item in enumerate(all_work) if idx % num_workers == i]
        work_per_worker.append(worker_items)
    
    return work_per_worker

def test_llama_model():
    """Test the Llama model with a simple query."""
    logging.info("Starting Llama model test...")
    logging.info(f"Testing Llama model: {MODELS['mistral']}")
    
    try:
        headers = {
            "Authorization": f"Bearer {TOGETHER_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": MODELS['mistral'],
            "prompt": "<system>You are a helpful assistant.</system><user>Say hello!</user><assistant>",
            "temperature": 0.7,
            "max_tokens": 100,
            "stop": ["</assistant>"]
        }
        
        # Add timeout to the request
        response = requests.post(
            "https://api.together.xyz/inference",
            headers=headers,
            json=data,
            timeout=30  # 30 second timeout
        )
        
        if response.status_code == 200:
            logging.info("✅ Test successful!")
            return True
        else:
            logging.error(f"Model test failed with status {response.status_code}: {response.text}")
            return False
            
    except requests.Timeout:
        logging.error("Model test timed out after 30 seconds")
        return False
    except Exception as e:
        logging.error(f"Error testing model: {str(e)}")
        return False

def main():
    """Main function to test and generate training data."""
    try:
        logging.info("\n=== Starting Training Data Generator ===")
        logging.info(f"Current time: {datetime.now().isoformat()}")
        
        # Test model connection
        logging.info("\n=== Testing Llama Model ===")
        test_success = test_llama_model()
        if not test_success:
            logging.error("Model test failed. Please check your Together AI API key and model configuration.")
            return
            
        # Ensure Supabase tables exist
        logging.info("\n=== Ensuring Supabase Tables Exist ===")
        ensure_tables_exist()
        
        # Store system context and rules
        logging.info("\n=== Storing System Context and Rules ===")
        store_system_context()
        
        # Generate and store training data
        generator = TrainingGenerator()
        
        # Generate examples for Shopify - Check Order Status
        tool = "Shopify"
        intent = "Check Order Status"
        logging.info(f"\nGenerating examples for {tool} - {intent}")
        
        # Generate examples with original batch size
        examples = generator.generate_examples_batch(tool, intent, count=5, batch_size=2)
        
        if examples:
            # Save to file
            output_file = os.path.join(OUTPUT_DIR, f"{tool}_{intent.replace(' ', '_')}_{len(examples)}.json")
            with open(output_file, 'w') as f:
                json.dump(examples, f, indent=2)
            logging.info(f"Saved examples to: {output_file}")
            
            # Insert into Supabase
            inserted = insert_examples_to_db(examples)
            logging.info(f"Inserted {inserted} examples for {tool} - {intent}")
            
            # Print the generated examples for verification
            logging.info("\nGenerated Examples:")
            for i, example in enumerate(examples, 1):
                logging.info(f"\nExample {i}:")
                logging.info(f"Query: {example['query']}")
                logging.info(f"Response: {example['response']}")
                logging.info(f"Follow-up: {example.get('follow_up', False)}")
        else:
            logging.warning(f"No examples were generated for {tool} - {intent}")
            
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        logging.error(traceback.format_exc())
        raise

if __name__ == "__main__":
    # Configure logging to write to both file and console
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('parallel_training_generator.log'),
            logging.StreamHandler()
        ]
    )
    
    try:
        main()
    except KeyboardInterrupt:
        logging.info("\nScript interrupted by user")
    except Exception as e:
        logging.error(f"Script failed with error: {str(e)}")
        logging.error(traceback.format_exc())
    finally:
        logging.info("Script finished")